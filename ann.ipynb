{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 1
        }, 
        {
            "source": "\nimport sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_21c44030ae6e4f07b01e9478fa35899f = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='dGYk0PkDUE4FGxeRuMaAzetB3Wm2dNvOCfVsYulfpk8N',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_21c44030ae6e4f07b01e9478fa35899f.get_object(Bucket='dlproject-donotdelete-pr-ilarxi2mwue2qv',Key='Churn_Modelling.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndataset = pd.read_csv(body)\n\nX = dataset.iloc[:, 3:13].values\ny = dataset.iloc[:, 13].values", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 2
        }, 
        {
            "source": "\n# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X_1 = LabelEncoder()\nX[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\nlabelencoder_X_2 = LabelEncoder()\nX[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\nonehotencoder = OneHotEncoder(categorical_features = [1])\nX = onehotencoder.fit_transform(X).toarray()\nX = X[:, 1:]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "# Part 2 - Now let's make the ANN!\n\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "# Initialising the ANN\nclassifier = Sequential()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 9
        }, 
        {
            "source": "# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 10
        }, 
        {
            "source": "\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/100\n8000/8000 [==============================] - 4s 490us/step - loss: 0.4977 - acc: 0.7985\nEpoch 2/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.4116 - acc: 0.8217\nEpoch 3/100\n8000/8000 [==============================] - 4s 487us/step - loss: 0.3989 - acc: 0.8254\nEpoch 4/100\n8000/8000 [==============================] - 4s 472us/step - loss: 0.3911 - acc: 0.8300\nEpoch 5/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.3859 - acc: 0.8299\nEpoch 6/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3824 - acc: 0.8295\nEpoch 7/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3789 - acc: 0.8315\nEpoch 8/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3771 - acc: 0.8300\nEpoch 9/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.3743 - acc: 0.8316\nEpoch 10/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3720 - acc: 0.8312\nEpoch 11/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3711 - acc: 0.8376\nEpoch 12/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3695 - acc: 0.8464\nEpoch 13/100\n8000/8000 [==============================] - 4s 476us/step - loss: 0.3681 - acc: 0.8480\nEpoch 14/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3668 - acc: 0.8482\nEpoch 15/100\n8000/8000 [==============================] - 4s 465us/step - loss: 0.3653 - acc: 0.8477\nEpoch 16/100\n8000/8000 [==============================] - 4s 475us/step - loss: 0.3644 - acc: 0.8502\nEpoch 17/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3637 - acc: 0.8525\nEpoch 18/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3626 - acc: 0.8525\nEpoch 19/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3616 - acc: 0.8516\nEpoch 20/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3614 - acc: 0.8522\nEpoch 21/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3605 - acc: 0.8535\nEpoch 22/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3602 - acc: 0.8534\nEpoch 23/100\n8000/8000 [==============================] - 4s 450us/step - loss: 0.3590 - acc: 0.8532\nEpoch 24/100\n8000/8000 [==============================] - 3s 435us/step - loss: 0.3585 - acc: 0.8524\nEpoch 25/100\n8000/8000 [==============================] - 4s 489us/step - loss: 0.3580 - acc: 0.8537\nEpoch 26/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3577 - acc: 0.8554\nEpoch 27/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3567 - acc: 0.8561\nEpoch 29/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3565 - acc: 0.8564\nEpoch 30/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3558 - acc: 0.8554\nEpoch 31/100\n8000/8000 [==============================] - 4s 475us/step - loss: 0.3552 - acc: 0.8567\nEpoch 32/100\n8000/8000 [==============================] - 4s 460us/step - loss: 0.3549 - acc: 0.8559\nEpoch 33/100\n8000/8000 [==============================] - 4s 476us/step - loss: 0.3545 - acc: 0.8567\nEpoch 34/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3541 - acc: 0.8556\nEpoch 35/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3541 - acc: 0.8569\nEpoch 36/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3531 - acc: 0.8565\nEpoch 37/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3532 - acc: 0.8570\nEpoch 38/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3528 - acc: 0.8550\nEpoch 39/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3530 - acc: 0.8562\nEpoch 40/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3521 - acc: 0.8570\nEpoch 41/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3519 - acc: 0.8584\nEpoch 42/100\n8000/8000 [==============================] - 4s 465us/step - loss: 0.3516 - acc: 0.8561\nEpoch 43/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3511 - acc: 0.8566\nEpoch 44/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3507 - acc: 0.8590\nEpoch 45/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3509 - acc: 0.8589\nEpoch 46/100\n8000/8000 [==============================] - 4s 472us/step - loss: 0.3501 - acc: 0.8581\nEpoch 47/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.3502 - acc: 0.8592\nEpoch 48/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3499 - acc: 0.8597\nEpoch 49/100\n8000/8000 [==============================] - 4s 453us/step - loss: 0.3495 - acc: 0.8595\nEpoch 50/100\n8000/8000 [==============================] - 4s 476us/step - loss: 0.3490 - acc: 0.8562\nEpoch 52/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3482 - acc: 0.8585\nEpoch 53/100\n8000/8000 [==============================] - 4s 477us/step - loss: 0.3480 - acc: 0.8582\nEpoch 56/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3471 - acc: 0.8589\nEpoch 57/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3472 - acc: 0.8575\nEpoch 58/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3466 - acc: 0.8602\nEpoch 59/100\n8000/8000 [==============================] - 4s 477us/step - loss: 0.3470 - acc: 0.8575\nEpoch 60/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3468 - acc: 0.8599\nEpoch 61/100\n8000/8000 [==============================] - 4s 475us/step - loss: 0.3467 - acc: 0.8606\nEpoch 62/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3463 - acc: 0.8579\nEpoch 63/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3466 - acc: 0.8591\nEpoch 64/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.3458 - acc: 0.8594\nEpoch 65/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3455 - acc: 0.8600\nEpoch 66/100\n8000/8000 [==============================] - 4s 472us/step - loss: 0.3454 - acc: 0.8579\nEpoch 67/100\n8000/8000 [==============================] - 4s 465us/step - loss: 0.3453 - acc: 0.8584\nEpoch 68/100\n8000/8000 [==============================] - 4s 450us/step - loss: 0.3451 - acc: 0.8605\nEpoch 69/100\n8000/8000 [==============================] - 4s 451us/step - loss: 0.3449 - acc: 0.8590\nEpoch 70/100\n8000/8000 [==============================] - 4s 452us/step - loss: 0.3443 - acc: 0.8599\nEpoch 71/100\n8000/8000 [==============================] - 4s 473us/step - loss: 0.3443 - acc: 0.8590\nEpoch 72/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3443 - acc: 0.8596\nEpoch 73/100\n8000/8000 [==============================] - 4s 451us/step - loss: 0.3434 - acc: 0.8591 1s - loss: \nEpoch 75/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3438 - acc: 0.8606\nEpoch 76/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3438 - acc: 0.8581\nEpoch 77/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3433 - acc: 0.8600\nEpoch 78/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3431 - acc: 0.8604\nEpoch 79/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3428 - acc: 0.8576\nEpoch 80/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3434 - acc: 0.8594\nEpoch 81/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3429 - acc: 0.8612\nEpoch 82/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3429 - acc: 0.8587\nEpoch 83/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3424 - acc: 0.8584\nEpoch 84/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3423 - acc: 0.8610\nEpoch 85/100\n8000/8000 [==============================] - 4s 465us/step - loss: 0.3419 - acc: 0.8597\nEpoch 86/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3423 - acc: 0.8582\nEpoch 87/100\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "8000/8000 [==============================] - 4s 462us/step - loss: 0.3426 - acc: 0.8589\nEpoch 88/100\n8000/8000 [==============================] - 4s 486us/step - loss: 0.3419 - acc: 0.8594\nEpoch 89/100\n8000/8000 [==============================] - 4s 464us/step - loss: 0.3420 - acc: 0.8590\nEpoch 90/100\n8000/8000 [==============================] - 4s 462us/step - loss: 0.3424 - acc: 0.8590\nEpoch 91/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3413 - acc: 0.8585\nEpoch 92/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3419 - acc: 0.8596\nEpoch 93/100\n8000/8000 [==============================] - 4s 461us/step - loss: 0.3417 - acc: 0.8589\nEpoch 94/100\n8000/8000 [==============================] - 4s 475us/step - loss: 0.3417 - acc: 0.8601\nEpoch 95/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3419 - acc: 0.8601\nEpoch 96/100\n8000/8000 [==============================] - 4s 474us/step - loss: 0.3413 - acc: 0.8599\nEpoch 97/100\n8000/8000 [==============================] - 4s 451us/step - loss: 0.3414 - acc: 0.8614\nEpoch 98/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3414 - acc: 0.8610\nEpoch 99/100\n8000/8000 [==============================] - 4s 463us/step - loss: 0.3409 - acc: 0.8597\nEpoch 100/100\n8000/8000 [==============================] - 4s 472us/step - loss: 0.3410 - acc: 0.8606\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x2af5c18b9f28>"
                    }, 
                    "execution_count": 11, 
                    "metadata": {}
                }
            ], 
            "execution_count": 11
        }, 
        {
            "source": "# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 13
        }, 
        {
            "source": "\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 14
        }, 
        {
            "source": "# ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}